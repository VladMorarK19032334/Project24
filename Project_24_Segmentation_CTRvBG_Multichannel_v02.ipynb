{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 24_Segmentation_CTRvBG_Multichannel_v02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19HJEPcXNY_4hNUi81PTlTlYVX49bjJYw",
      "authorship_tag": "ABX9TyNDovB6jKCIpe1rKKBuWArg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladMorarK19032334/Project24/blob/main/Project_24_Segmentation_CTRvBG_Multichannel_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic7jh2_L1Cks",
        "outputId": "0c81a2d6-80d6-4e55-df33-13e40b745082"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 28 14:48:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkR1tzFJ3BlH"
      },
      "source": [
        "!pip install tenserflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Id7x0p3MEe"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvjc5aG93rrs"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCqUwYMY39Yq"
      },
      "source": [
        "!pip install albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check versions for updates"
      ],
      "metadata": {
        "id": "tRXoPx4nFHY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V\n",
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quj3NtEdFGuo",
        "outputId": "3f31b900-1302-4532-a2d7-43d70182d00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "GtA8-sj3DzXl",
        "outputId": "7fbd6db7-bb45-44ea-da35-99aeee5cfb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 98.9 MB/s eta 0:00:12tcmalloc: large alloc 1147494400 bytes == 0x56455c5dc000 @  0x7ffa50b1c615 0x564521f5c4cc 0x56452203c47a 0x564521f5f2ed 0x564522050e1d 0x564521fd2e99 0x564521fcd9ee 0x564521f60bda 0x564521fd2d00 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564521f61039 0x564521fa4409 0x564521f5fc52 0x564521fd2c25 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f60bda 0x564521fce915 0x564521f60afa 0x564521fcec0d 0x564521fcd9ee\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.6 MB/s eta 0:09:55tcmalloc: large alloc 1434370048 bytes == 0x5645a0c32000 @  0x7ffa50b1c615 0x564521f5c4cc 0x56452203c47a 0x564521f5f2ed 0x564522050e1d 0x564521fd2e99 0x564521fcd9ee 0x564521f60bda 0x564521fd2d00 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564521f61039 0x564521fa4409 0x564521f5fc52 0x564521fd2c25 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f60bda 0x564521fce915 0x564521f60afa 0x564521fcec0d 0x564521fcd9ee\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 33.7 MB/s eta 0:00:20tcmalloc: large alloc 1792966656 bytes == 0x564525a64000 @  0x7ffa50b1c615 0x564521f5c4cc 0x56452203c47a 0x564521f5f2ed 0x564522050e1d 0x564521fd2e99 0x564521fcd9ee 0x564521f60bda 0x564521fd2d00 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564521f61039 0x564521fa4409 0x564521f5fc52 0x564521fd2c25 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f60bda 0x564521fce915 0x564521f60afa 0x564521fcec0d 0x564521fcd9ee\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 50.6 MB/s eta 0:00:06tcmalloc: large alloc 2241208320 bytes == 0x56459084c000 @  0x7ffa50b1c615 0x564521f5c4cc 0x56452203c47a 0x564521f5f2ed 0x564522050e1d 0x564521fd2e99 0x564521fcd9ee 0x564521f60bda 0x564521fd2d00 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564522051c66 0x564521fcedaf 0x564521f61039 0x564521fa4409 0x564521f5fc52 0x564521fd2c25 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f60bda 0x564521fce915 0x564521f60afa 0x564521fcec0d 0x564521fcd9ee\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x5646161ae000 @  0x7ffa50b1b1e7 0x564521f92067 0x564521f5c4cc 0x56452203c47a 0x564521f5f2ed 0x564522050e1d 0x564521fd2e99 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521f60afa 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x56470089e000 @  0x7ffa50b1c615 0x564521f5c4cc 0x56452203c47a 0x564521f5f2ed 0x564522050e1d 0x564521fd2e99 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcec0d 0x564521f60afa 0x564521fcec0d 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f60bda 0x564521fcf737 0x564521fcd9ee 0x564521f61271\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 2.5 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 35 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.5.1+cu101\n",
            "    Uninstalling torch-1.5.1+cu101:\n",
            "      Successfully uninstalled torch-1.5.1+cu101\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.6.1+cu101\n",
            "    Uninstalling torchvision-0.6.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.1+cu101\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM6KC_qf4M4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a62aa5-808d-4fe1-c94f-5c77fef61bf7"
      },
      "source": [
        "!pip install pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Building wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-lm38e620/pytorch_f67fe0556f3d49ce9a8a133f8e381384/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-lm38e620/pytorch_f67fe0556f3d49ce9a8a133f8e381384/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-p12rchi0/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/pytorch Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO-uj--482r"
      },
      "source": [
        "#!pip install albumentations==0.4.6\n",
        "'''\n",
        "!pip install --upgrade --force-reinstall --no-deps albumentations\n",
        "!pip install qudida\n",
        "#!pip install albumentations==0.4.6\n",
        "#import albumentations \n",
        "#from albumentations.pytorch import ToTensorV2\n",
        "'''\n",
        "#!pip uninstall albumentations\n",
        "#!pip install albumentations==0.4.6\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R7XKD2A3eRc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "#import albumentations as A\n",
        "#from albumentations.torch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#from UNET import UNET\n",
        "import torch\n",
        "import torchvision\n",
        "#from data import CTRDatasetNpy\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uTGxxrDT29M"
      },
      "source": [
        "Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXWaUzZJT53p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c72feb7a-dc11-4ec2-d3f9-5c578252f34e"
      },
      "source": [
        "'''\n",
        "!pip install tensorboard\n",
        "\n",
        "tensorboard dev upload --logdir logs \\\n",
        "    --name \"(optional) My latest experiment\" \\\n",
        "    --description \"(optional) Simple comparison of several hyperparameters\"\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!pip install tensorboard\\n\\ntensorboard dev upload --logdir logs     --name \"(optional) My latest experiment\"     --description \"(optional) Simple comparison of several hyperparameters\"\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyByJ3Ck5bbr"
      },
      "source": [
        "UNET CLASSES (Neural Network Setup for UNET)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxEYil6r5WH-"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    # output 3 channels (3 tubes)\n",
        "    def __init__(\n",
        "            self, in_channels=3, out_channels=4, features=[64, 128, 256, 512]):\n",
        "        super(UNET, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET (downsampling)\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET (upsampling)\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        # final 2d layer\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1] # reverse list\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2] # integer division\n",
        "\n",
        "            # check if their shapes does not match => makes it generalize\n",
        "            if x.shape != skip_connection.shape:\n",
        "                # do resizing\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzN6tLLO5pLR"
      },
      "source": [
        "DATA PROCESSING STEP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AntSSLWL5j2J"
      },
      "source": [
        "# loading dataset of numpy format\n",
        "class CTRDatasetNpy(Dataset):\n",
        "    def __init__(self, images_file, masks_file, transform=None):\n",
        "        self.images_file = images_file\n",
        "        self.masks_file = masks_file\n",
        "        self.transform = transform\n",
        "        self.images = np.load(images_file) # load numpy data of all images\n",
        "        self.masks = np.load(masks_file) # load numpy data of all masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        mask = self.masks[index] # mask data is already normalized\n",
        "\n",
        "        if self.transform is not None: # do data augmentation\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGAIhYGw53CY"
      },
      "source": [
        "Utilities Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wGGzr4K5tcG"
      },
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "\n",
        "def get_loaders(\n",
        "    train_dir,\n",
        "    train_maskdir,\n",
        "    val_dir,\n",
        "    val_maskdir,\n",
        "    batch_size,\n",
        "    train_transform,\n",
        "    val_transform,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    train_ds = CTRDatasetNpy(\n",
        "        train_dir,\n",
        "        train_maskdir,\n",
        "        train_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    val_ds = CTRDatasetNpy(\n",
        "        val_dir,\n",
        "        val_maskdir,\n",
        "        val_transform,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "# Needed to be adapted for multichannel (This is for binary)\n",
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device).unsqueeze(1)\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            \n",
        "            dice_score += (2 * (preds * y).sum()) / (\n",
        "                (preds + y).sum() + 1e-8\n",
        "            )\n",
        "\n",
        "    print(\n",
        "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
        "    )\n",
        "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def save_predictions_as_imgs(\n",
        "    loader, model, saved_image_index, folder=\"/content/drive/MyDrive/Biomed 3rd Year/BEng Project/Training Datasets/CTRvBG_Multichannel_v01/UNet_Aug_OutputSizeColor_v02/\", device=\"cuda\"):\n",
        "    model.eval()\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "\n",
        "            # *** NEW *** set colors based on probabilities\n",
        "            preds = (preds < 0.25).float(); # BG\n",
        "\n",
        "\n",
        "            ## segmentation output processing\n",
        "            preds = (preds * (255/4)).float()\n",
        "            print(torch.unique(preds))\n",
        "\n",
        "            torchvision.utils.save_image(\n",
        "              preds, f\"{folder}/pred_{saved_image_index}.png\", normalize=True\n",
        "            ) # save pred\n",
        "            print(f\"Saved prediction: {saved_image_index}\")\n",
        "        # ERROR LINE\n",
        "        #torchvision.utils.save_image(x.unsqueeze(1), f\"{folder}/image_{saved_image_index}.png\", normalize=True) # save image\n",
        "        torchvision.utils.save_image(y.float().unsqueeze(1), f\"{folder}/mask_{saved_image_index}.png\", normalize=True) # save mask\n",
        "        print(f\"Saved image: {saved_image_index}\")\n",
        "\n",
        "    model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW5dh0DL5-_y"
      },
      "source": [
        "TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gFbyblG6Amp"
      },
      "source": [
        "# Hyperparameters\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 7\n",
        "NUM_EPOCHS = 100\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 480  # original size: 480px\n",
        "IMAGE_WIDTH = 640  # original size: 640px\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "TRAIN_IMG_DIR = \"/content/drive/MyDrive/Biomed 3rd Year/BEng Project/Training Datasets/CTRvBG_Multichannel/imgs3_train.npy\"\n",
        "TRAIN_MASK_DIR = \"/content/drive/MyDrive/Biomed 3rd Year/BEng Project/Training Datasets/CTRvBG_Multichannel/masks3_train.npy\"\n",
        "VAL_IMAGE_DIR = \"/content/drive/MyDrive/Biomed 3rd Year/BEng Project/Training Datasets/CTRvBG_Multichannel/imgs3_val.npy\"\n",
        "VAL_MASK_DIR = \"/content/drive/MyDrive/Biomed 3rd Year/BEng Project/Training Datasets/CTRvBG_Multichannel/masks3_val.npy\"\n",
        "\n",
        "SAVE_OUTPUT_FOLDER = \"/content/drive/MyDrive/Biomed 3rd Year/BEng Project/Training Datasets/CTRvBG_Multichannel/UNet_Aug_OutputSizeColor_v02/\"\n",
        "\n",
        "torch.cuda.empty_cache() # empty cuda cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd4XnK2FWSAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "9bd61c03-183b-471c-a88e-ee803f840ca5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXNRlQeX6F6_"
      },
      "source": [
        "# does 1 Epoch of training\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "    loop = tqdm(loader) # progress bar\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.long().to(device=DEVICE)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            #targets = targets.long().to(device=DEVICE)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update tqdm loop\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpl5UfCi6H9L",
        "outputId": "6fd62d6d-4c67-495b-baba-67e0f6de7d3f"
      },
      "source": [
        "def main():\n",
        "    _saved_image_index = 0\n",
        "\n",
        "    train_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    val_transforms = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0, # divide by 255\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    model = UNET(in_channels=3, out_channels=4).to(DEVICE)\n",
        "    loss_fn = nn.CrossEntropyLoss() # necessary because sigmoid was not used on the model\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    train_loader, val_loader = get_loaders(\n",
        "        TRAIN_IMG_DIR,\n",
        "        TRAIN_MASK_DIR,\n",
        "        VAL_IMAGE_DIR,\n",
        "        VAL_MASK_DIR,\n",
        "        BATCH_SIZE,\n",
        "        train_transform,\n",
        "        val_transforms,\n",
        "        NUM_WORKERS,\n",
        "        PIN_MEMORY,\n",
        "    )\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
        "    \n",
        "    check_accuracy(val_loader, model, device=DEVICE)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        torch.cuda.empty_cache() # empty cuda cache\n",
        "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
        "\n",
        "        # save model\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "        # check accuracy\n",
        "        check_accuracy(val_loader, model, device=DEVICE)\n",
        "\n",
        "        # print examples every 5 epochs\n",
        "        if _saved_image_index%10 == 0 or _saved_image_index == 0 or _saved_image_index == 99:\n",
        "          # print some examples to a folder\n",
        "          save_predictions_as_imgs(\n",
        "              val_loader, model, _saved_image_index, SAVE_OUTPUT_FOLDER, device=DEVICE\n",
        "          )\n",
        "\n",
        "        _saved_image_index += 1\n",
        "        \n",
        "\n",
        "torch.backends.cudnn.enabled = False\n",
        "# train model\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 106124/20889600 with acc 0.51\n",
            "Dice score: 0.03694304823875427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:19<00:00,  1.93s/it, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 5261638/20889600 with acc 25.19\n",
            "Dice score: 0.03668162599205971\n",
            "tensor([0.], device='cuda:0')\n",
            "Saved prediction: 0\n",
            "Saved image: 0\n",
            "tensor([0.], device='cuda:0')\n",
            "Saved prediction: 0\n",
            "Saved image: 0\n",
            "tensor([0.], device='cuda:0')\n",
            "Saved prediction: 0\n",
            "Saved image: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:19<00:00,  1.97s/it, loss=0.999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 13509504/20889600 with acc 64.67\n",
            "Dice score: 0.05236957594752312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:20<00:00,  2.01s/it, loss=0.884]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 15093447/20889600 with acc 72.25\n",
            "Dice score: 0.04723116010427475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:20<00:00,  2.05s/it, loss=0.948]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Got 15211810/20889600 with acc 72.82\n",
            "Dice score: 0.046103060245513916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZeOhE_k7lwZ"
      },
      "source": [
        "Run training"
      ]
    }
  ]
}